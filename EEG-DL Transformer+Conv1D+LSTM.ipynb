{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvg3DrbQ+sZAEQskXzhWdT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yG7FtA8pLESz"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"id":"8AzKXcW3LNz0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"id":"vwHrox8FLPja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.io import loadmat\n","# Replace 'your_file.mat' with the path to your actual .mat file\n","mat = loadmat('/content/gdrive/MyDrive/inputdata.mat')\n","# mat is now a dictionary with variable names as keys and loaded matrices as values\n","# To access a variable named 'VariableName' stored in the .mat file, use:\n","X = mat['inputdata']\n","# Now, data contains the array stored in 'VariableName'. You can manipulate it as needed."],"metadata":{"id":"G4oJffS0LRU6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.io import loadmat\n","# Replace 'your_file.mat' with the path to your actual .mat file\n","mat = loadmat('/content/gdrive/MyDrive/labeldata.mat')\n","# mat is now a dictionary with variable names as keys and loaded matrices as values\n","# To access a variable named 'VariableName' stored in the .mat file, use:\n","y = mat['labeldata']\n","# Now, data contains the array stored in 'VariableName'. You can manipulate it as needed."],"metadata":{"id":"A6G5MqTALT_D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import required libraries\n","from tensorflow.keras.models import Sequential, Model, load_model\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM, Input, MultiHeadAttention, LayerNormalization, concatenate, GlobalAveragePooling1D, BatchNormalization\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, roc_curve, auc, cohen_kappa_score\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Assuming X and y are preloaded datasets\n","# Ensure y is processed for categorical classification\n","y_categorical = to_categorical(y) if y.ndim == 1 else y\n","\n","# Split the data into train, validation, and test sets\n","X_temp, X_test, y_temp, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n","\n","# Reshape X matrices to 3D if they are 2D, for Conv1D layers\n","for dataset in [X_train, X_test, X_val]:\n","    if dataset.ndim == 2:\n","        dataset = dataset.reshape(dataset.shape[0], dataset.shape[1], 1)\n","\n","# Define the transformer encoder component\n","def transformer_encoder(inputs, num_heads=4, ff_dim=64, sequence_length=18):\n","    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=ff_dim)(inputs, inputs)\n","    attention_output = Dropout(0.1)(attention_output)\n","    out1 = LayerNormalization(epsilon=1e-6)(inputs + attention_output)\n","    ff_output = Dense(ff_dim, activation=\"relu\")(out1)\n","    ff_output = Dropout(0.1)(ff_output)\n","    ff_output = Dense(sequence_length, activation=\"relu\")(ff_output)\n","    return LayerNormalization(epsilon=1e-6)(out1 + ff_output)\n","\n","# Model creation\n","def create_model(sequence_length=18, num_classes=2):\n","    inputs = Input(shape=(sequence_length, 1))\n","    x1 = Conv1D(filters=32, kernel_size=3, activation='relu')(inputs)\n","    x1 = BatchNormalization()(x1)\n","    x1 = MaxPooling1D(pool_size=2)(x1)\n","    x1 = LSTM(64, return_sequences=False)(x1)\n","    x2 = transformer_encoder(inputs)\n","    x2 = GlobalAveragePooling1D()(x2)\n","    merged = concatenate([x1, x2])\n","    x = Dense(128, activation='relu')(merged)\n","    x = Dropout(0.2)(x)\n","    outputs = Dense(num_classes, activation='softmax')(x)\n","    model = Model(inputs=inputs, outputs=outputs)\n","    return model\n","\n","# Initialize and compile the model\n","model = create_model(sequence_length=X_train.shape[1], num_classes=y_categorical.shape[1])\n","model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Define callbacks\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1),\n","    ModelCheckpoint(filepath='best_hybrid_model.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1),\n","    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-5, verbose=1)\n","]\n","\n","# Train the model\n","history = model.fit(X_train, y_train, batch_size=64, epochs=30, validation_data=(X_val, y_val), callbacks=callbacks)\n","\n","# Load the best model\n","model = load_model('best_hybrid_model.h5')\n","\n","# Predict and evaluate\n","y_pred_prob = model.predict(X_test)\n","y_pred = np.argmax(y_pred_prob, axis=1)\n","y_true = np.argmax(y_test, axis=1)\n","print(classification_report(y_true, y_pred))\n","\n","# Plot accuracy and loss\n","plt.figure(figsize=(14, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'], label='Train')\n","plt.plot(history.history['val_accuracy'], label='Val')\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='Train')\n","plt.plot(history.history['val_loss'], label='Val')\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.show()\n","\n","# Plot ROC curve\n","fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob[:, 1])\n","roc_auc = auc(fpr, tpr)\n","plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","# Calculate and print Kappa Score\n","kappa_value = cohen_kappa_score(y_true, y_pred)\n","print(f'Kappa Score: {kappa_value}')"],"metadata":{"id":"Ah0rSqVMLWM4"},"execution_count":null,"outputs":[]}]}